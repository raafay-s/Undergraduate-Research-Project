{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGuLjroS3b1xGxTeHSjrbE"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XBEN-tGQd9F"
      },
      "outputs": [],
      "source": [
        "!pip install google-api-python-client\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "# Enter unique API key\n",
        "api_key = input(\"Please enter your YouTube API key: \")\n",
        "if not api_key:\n",
        "    print(\"Error: API key is required!\")\n",
        "    exit()\n",
        "\n",
        "# Initialize the YouTube API\n",
        "youtube = build('youtube', 'v3', developerKey=api_key)\n",
        "\n",
        "# Your list of video URLs\n",
        "video_urls = [\n",
        "    \"https://www.youtube.com/watch?v=83IWEkCgFi0\",\n",
        "    \"https://www.youtube.com/watch?v=9bdab8_JMrw\",\n",
        "    \"https://www.youtube.com/watch?v=AIX8DCZRI18\",\n",
        "    \"https://www.youtube.com/watch?v=SoEJijhfHuE\",\n",
        "    \"https://www.youtube.com/watch?v=nBYmolDbxgA\",\n",
        "    \"https://www.youtube.com/watch?v=IcLjyTCxvRU\",\n",
        "    \"https://www.youtube.com/watch?v=Ot1BYJP8Dig\",\n",
        "    \"https://www.youtube.com/watch?v=7P1qTwlGeuY\",\n",
        "    \"https://www.youtube.com/watch?v=A6wmG7QqaOk\"\n",
        "    \"https://www.youtube.com/watch?v=IiZRR1vIlhY\"\n",
        "]\n",
        "\n",
        "# Function to extract video ID from URL\n",
        "def extract_video_id(url):\n",
        "    match = re.search(r\"v=([a-zA-Z0-9_-]+)\", url)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "# Function to get comments from a video\n",
        "def get_comments(video_id):\n",
        "    comments = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        response = youtube.commentThreads().list(\n",
        "            part=\"snippet\",\n",
        "            videoId=video_id,\n",
        "            maxResults=100,\n",
        "            pageToken=next_page_token,\n",
        "            textFormat=\"plainText\"\n",
        "        ).execute()\n",
        "\n",
        "        for item in response.get(\"items\", []):\n",
        "            comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
        "            comments.append({\n",
        "                \"video_id\": video_id,\n",
        "                \"author\": comment[\"authorDisplayName\"],\n",
        "                \"published_at\": comment[\"publishedAt\"],\n",
        "                \"text\": comment[\"textDisplay\"],\n",
        "                \"like_count\": comment[\"likeCount\"]\n",
        "            })\n",
        "\n",
        "        next_page_token = response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return comments\n",
        "\n",
        "# Extract comments for each video\n",
        "all_comments = []\n",
        "for url in video_urls:\n",
        "    video_id = extract_video_id(url)\n",
        "    print(f\"Collecting comments from video: {video_id}\")\n",
        "    try:\n",
        "        video_comments = get_comments(video_id)\n",
        "        all_comments.extend(video_comments)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed for video {video_id}: {e}\")\n",
        "\n",
        "# Convert to DataFrame and save to CSV\n",
        "df = pd.DataFrame(all_comments)\n",
        "df.to_csv(\"youtube_helene_comments.csv\", index=False)\n",
        "print(\"Comments saved to 'youtube_helene_comments.csv'\")"
      ]
    }
  ]
}
