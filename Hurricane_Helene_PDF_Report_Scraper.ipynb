{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install pdfplumber library to extract text from PDFs\n",
        "!pip install pdfplumber\n",
        "\n",
        "# Import necessary libraries\n",
        "import pdfplumber\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from google.colab import files  # For file download (works in Google Colab)\n",
        "\n",
        "# List of keywords related to economic topics (e.g., damage, investment, housing)\n",
        "keywords = [\n",
        "    \"economic\", \"loss\", \"damage\", \"impact\", \"investment\", \"unmet\", \"cost\", \"expenditure\",\n",
        "    \"estimate\", \"revenue\", \"budget\", \"expenses\", \"repair\", \"relief\", \"insurance\",\n",
        "    \"business\", \"property\", \"crop\", \"recovery\", \"housing\", \"infrastructure\", \"funding\"\n",
        "]\n",
        "\n",
        "# Compile a regular expression to match dollar amounts (e.g., \"$1 million\" or \"$500,000\")\n",
        "dollar_regex = re.compile(r'\\$\\s?\\d[\\d,]*(\\.\\d+)?\\s?(billion|million)?', re.IGNORECASE)\n",
        "\n",
        "# Initialize an empty list to store the relevant paragraphs found\n",
        "relevant_data = []\n",
        "\n",
        "# Loop through all PDFs in the current directory\n",
        "for filename in os.listdir():\n",
        "    # Check if the file is a PDF\n",
        "    if filename.endswith(\".pdf\"):\n",
        "        with pdfplumber.open(filename) as pdf:\n",
        "            # Loop through each page of the PDF\n",
        "            for page in pdf.pages:\n",
        "                text = page.extract_text()\n",
        "                if not text:\n",
        "                    continue\n",
        "\n",
        "                # Split the extracted text into paragraphs using two or more newlines\n",
        "                paragraphs = re.split(r'\\n{2,}', text)\n",
        "\n",
        "                # Loop through each paragraph to check for keywords or dollar amounts\n",
        "                for para in paragraphs:\n",
        "                    # Clean up the paragraph by stripping extra spaces and replacing line breaks with spaces\n",
        "                    para_clean = para.strip().replace(\"\\n\", \" \")\n",
        "\n",
        "                    # Check if any keyword is present in the paragraph (case-insensitive)\n",
        "                    keyword_found = any(k in para_clean.lower() for k in keywords)\n",
        "                    # Check if a dollar amount is present in the paragraph\n",
        "                    dollar_found = bool(dollar_regex.search(para_clean))\n",
        "\n",
        "                    # If a keyword or dollar amount is found, add the paragraph to the relevant data list\n",
        "                    if keyword_found or dollar_found:\n",
        "                        relevant_data.append({\n",
        "                            \"filename\": filename,  # Store the filename for reference\n",
        "                            \"paragraph\": para_clean  # Store the cleaned paragraph text\n",
        "                        })\n",
        "\n",
        "# Convert the list of relevant paragraphs into a DataFrame for easier handling\n",
        "df = pd.DataFrame(relevant_data)\n",
        "\n",
        "# Define the CSV filename to save the results\n",
        "csv_filename = \"relevant_paragraphs.csv\"\n",
        "\n",
        "# Save the DataFrame as a CSV file\n",
        "df.to_csv(csv_filename, index=False)\n",
        "\n",
        "# Download the CSV file (this works in Google Colab)\n",
        "files.download(csv_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "3JDfghkAGKrn",
        "outputId": "b22876b8-eec6-4d42-abe1-0d46016900d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (0.11.6)\n",
            "Requirement already satisfied: pdfminer.six==20250327 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (20250327)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.2.1)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (4.30.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_01ab6a95-da84-43ef-a974-a6f2b2d6c2e4\", \"relevant_paragraphs.csv\", 373015)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Done! File downloaded. Total relevant paragraphs: 141\n"
          ]
        }
      ]
    }
  ]
}